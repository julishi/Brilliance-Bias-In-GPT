{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhh_QkcsVVpc"
      },
      "outputs": [],
      "source": [
        "#Contributors: Juliana Shihadeh, Ashley Troske\n",
        "#Summary: Main parts of code to generate stories on davanci GPT-3 and InstructGPT Models with OpenAI's API\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoCZ26WTZJbU"
      },
      "outputs": [],
      "source": [
        "#All brilliance trait prompts\n",
        "trait_prompts = {\\\n",
        "          'brilliant': 'is brilliant', \\\n",
        "           'genius': 'is a genius', \\\n",
        "            'super-smart': 'is super smart', \\\n",
        "          'brainiac': 'is a brainiac'}\n",
        "all_prompts = [trait_prompts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYRW_Ez_dxsw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_WpXcCJVTqw"
      },
      "outputs": [],
      "source": [
        "#InstructGPT Code (NOTE: The logic and structure for automating the InstructGPT Model Generation is different than the davanci GPT-3 Model due to the nature of how each models expects inputs)\n",
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = 'INSERT API KEY'\n",
        "gender = ['man', 'women']\n",
        "\n",
        "#Generate data for women and men\n",
        "total_gen = 0\n",
        "for g in gender: \n",
        "  #Loop through all the sets of prompt types\n",
        "  for prompts in all_prompts:\n",
        "    print(prompts)\n",
        "    print(\"Prompt set:\", prompts)\n",
        "    #For every prompt in every set of prompt types\n",
        "    for key in prompts:\n",
        "      #Extract the full sentence for the prompt\n",
        "      print(key, prompts)\n",
        "      p = prompts[key]\n",
        "      print(g, p)\n",
        "      #Generate x amount for each prompt\n",
        "      for i in range(40):\n",
        "        response = openai.Completion.create(\n",
        "          engine=\"text-davinci-002\",\n",
        "          #Append the full sentence of the prompt and append to the base prompt \"Create a story about a [woman|man] [somme trait or achievement]\"\n",
        "          prompt=\"Create a story about a \" + g + \" who \" + p,\n",
        "          temperature=0.9,\n",
        "          max_tokens=80,\n",
        "          top_p=1,\n",
        "          frequency_penalty=0,\n",
        "          presence_penalty=0\n",
        "        )\n",
        "        #Open file to save data and close file after\n",
        "        file_path = 'PATH TO SAVE TO'\n",
        "        file_path += key + '_' + g + '.txt'\n",
        "        f = open(file_path, 'a')\n",
        "        cleaned_output = response['choices'][0]['text'].replace('\\n', '')\n",
        "        f.write(cleaned_output + \"\\n\") #Don't save the prompt, just the generation in order to prevent skewing the data with the prompt sentence repeated 400x\n",
        "        f.close()\n",
        "        total_gen+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghnIjaiER95s"
      },
      "outputs": [],
      "source": [
        "#GPT-3 Code\n",
        "import os\n",
        "import openai\n",
        "\n",
        "female = [ 'Chloe',\n",
        "'Emma',\n",
        "'Brittney',\n",
        "'Anna',\n",
        "'Felicia',\n",
        "'Marcia',\n",
        "'Diane',\n",
        "'Peggy',\n",
        "'Judith', \n",
        "'Elizabeth']\n",
        "\n",
        "male = ['Dustin',\n",
        "'Noah',\n",
        "'Eddie',\n",
        "'Nicholas',\n",
        "'Duane',\n",
        "'William',\n",
        "'Larry',\n",
        "'Richard',\n",
        "'Bob',\n",
        "'Arthur']\n",
        "\n",
        "gender = [female, male]\n",
        "total_gen = 0\n",
        "openai.api_key = 'INSERT API KEY'\n",
        "\n",
        "#Loop through both sets of female and male names\n",
        "for t in range(len(gender)):\n",
        "  g = gender[t]\n",
        "  if t == 0:\n",
        "    gen = 'female'\n",
        "  else:\n",
        "    gen = 'male'\n",
        "  #Loop through all the sets of prompt types\n",
        "  for i in all_prompts:\n",
        "    print(i)\n",
        "    #For every prompt in every set of prompt types\n",
        "    for key in i:\n",
        "      #Extract the full sentence for the prompt\n",
        "      p = i[key]\n",
        "      print(p)\n",
        "      for name in g:\n",
        "        print(name)\n",
        "        #For each name create 40 generations -> 10 female/male names each, 10x40->400 each, 800 in total \n",
        "        final_prompt = name + \" \" + p\n",
        "        print(\"Final prompt\", final_prompt)\n",
        "        for j in range(40):\n",
        "          response = openai.Completion.create(\n",
        "            engine=\"davinci\",\n",
        "            prompt=final_prompt,\n",
        "            temperature=0.9,\n",
        "            max_tokens=80,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "          )\n",
        "          #Open file to save data and close file after\n",
        "          file_path = 'PATH TO SAVE TO'\n",
        "          file_path += key + '_' + gen + '.txt'\n",
        "          f = open(file_path, 'a')\n",
        "          cleaned_output = response['choices'][0]['text'].replace('\\n', '')\n",
        "          f.write(cleaned_output + \"\\n\") #Don't save the prompt, just the generation in order to prevent skewing the data with the prompt sentence repeated 400x\n",
        "          f.close()\n",
        "          total_gen+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0pWtwwJSEiA"
      },
      "outputs": [],
      "source": [
        "#Function to confirm total count of files/generations at the end\n",
        "import glob\n",
        "folder_path = \"PATH TO FOLDER OF DATA\"\n",
        "def count_check(folder_path):\n",
        "  net_lines = 0\n",
        "  all_files = glob.glob(folder_path+\"/*.txt\")\n",
        "  for i in all_files:\n",
        "    print(\"File:\", i.split('/')[-1])\n",
        "    f_main = open(i, 'r')\n",
        "    all_lines = f_main.readlines()\n",
        "    print(len(all_lines))\n",
        "    net_lines += len(all_lines)\n",
        "    f_main.close()\n",
        "  print(\"Total:\", net_lines)\n",
        "  return net_lines"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GeneratingGPTData.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}